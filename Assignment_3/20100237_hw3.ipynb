{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Home work 3\n",
    "###### 20100237"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this home work is to design convolutional neural network for classification task on two dataset (a) cifar10 (b) Bricklane. As a part of this home work you will implement convolutional neural network in python and then study the effect of pooling, dropout, batch normalization and learning rate for given classifcation task. \n",
    "<br>\n",
    "Please note:\n",
    "- You have to save each trained model weights and tensorboard logs in different folder. Use proper names for the model\n",
    "- You have to show trainings in this notebook file, so make sure that the printings and figures are available on this notebook file\n",
    "- This notebook is also your report file. So add your comments and analysis of each task. This would be considered short report and it is compulsory part of the homework.\n",
    "- Your system memory may overflow. In that case please reset memory for trained model(s) keeping printed logs and history of trained model. History of all trained models could be used to plot the trends.\n",
    "- For trends you shall also use tensorboard logs \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau, TensorBoard\n",
    "from keras.utils import plot_model, to_categorical\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "#import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "your_id = 20100237\n",
    "np.random.seed(your_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "class_labels = np.arange(0, num_classes, 1)\n",
    "input_shape = (32,32,3)\n",
    "images_dir = 'images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.1   Load dataset information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[_cifar10_](https://www.cs.toronto.edu/~kriz/cifar.html) dataset contains 10 classes including airplane, bird, cat etc. You need to download dataset from [LINK](http://pjreddie.com/media/files/cifar.tgz) or [LINK2](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). \n",
    "<br> _cifar10_ dataset is also available in keras but it is recommended to use the downloaded from above given link as ```cifar10.load_data()``` function downloads and loads complete data on RAM. \n",
    "<br> <br>\n",
    "This [Github](https://github.com/EN10/CIFAR) link may be helpful to you to load _cifar10_ dataset yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "# The data, split between train and test sets:\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=your_id)\n",
    "# print('x_train shape:', x_train.shape)\n",
    "# print(x_train.shape[0], 'train samples')\n",
    "# print(x_test.shape[0], 'test samples')\n",
    "# print(y_train[0])\n",
    "# # url = http://pjreddie.com/media/files/cifar.tgz\n",
    "# #\n",
    "\n",
    "# # Convert class vectors to binary class matrices.\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "train_dir = './cifar/train/'\n",
    "test_dir = './cifar/test/'\n",
    "\n",
    "train_data = np.array(glob.glob(train_dir + '*.png'))\n",
    "test_data = np.array(glob.glob(test_dir + '*.png'))\n",
    "with open(t)\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of data such as normalization, mean shift, make the learning task simple for network and could accelrate the training process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1.2.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the images, pixel values vary from 0 to 255. To shift the values between (0,1) range, divide input image by 255. Now, retrain the model designed in part-A from scratch with preprocessed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You shall add your code here\n",
    "def preprocessing_norm (images):\n",
    "    #Add code here\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1.2.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the images, pixel values vary from 0 to 255. Compute the channel wise mean and standard daviation (std) for whole dataset. subtract channel-wise mean and divide by channel-wise std. This will shift the mean to zero and varation to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You shall add your code here\n",
    "def preprocessing_meanShift (images):\n",
    "    #Add code here\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.3  Batch Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training, we load complete data (inputs, outputs) into RAM and then provide it to \"model.fit\" function. However, in real when dataset is very large in size we can not load complete data on RAM. In that case, we need load data batchwise. To do this, we need to write a generator function that shall load a batch of data (images and output), preprocess images and return a tuple as (inputs, outputs) on every step. \n",
    "<br>\n",
    "- The template code for batch generator is provided. You need add you script to read image(s), labels and preprocessing of images. \n",
    "<br>\n",
    "- You need to check and control values of batch_start and batch_end \n",
    "<br>\n",
    "- Batch generator can be implemented in multiple ways. You can use any other template of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path(filename):\n",
    "    i = filename.rfind('_')+1\n",
    "    j = filename.rfind('.')\n",
    "    return filename[i:j]\n",
    "    \n",
    "def get_image(filename):\n",
    "    return cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def data_generator(images_paths, batch_size = 64, preprocessing = None):\n",
    "    i = 0\n",
    "    total_size = len(images_paths)\n",
    "    \n",
    "    print(total_size)\n",
    "    while(i < 2):\n",
    "        j = min(total_size, i+batch_size)\n",
    "        batch_paths = images_paths[i:j]\n",
    "        i += batch_size\n",
    "        \n",
    "        batch_x = np.array([get_image(path) for path in batch_paths])\n",
    "        batch_y = np.array([parse_path(path) for path in batch_paths])\n",
    "        \n",
    "        yield(batch_x, batch_y)\n",
    "#         if (preprocessing is None):\n",
    "#             pass\n",
    "#         elif (preprocessing == 'method1'):\n",
    "#             batch_images = preprocessing_norm(batch_images)\n",
    "#         else:\n",
    "#             batch_images = preprocessing_meanShift(batch_images)\n",
    "\n",
    "#         yield( batch_x, batch_y )\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'bird'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d837b9fb29f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(all_data[0][0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mall_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mall_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# all_ys = to_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_ys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning/lib/python3.6/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'bird'"
     ]
    }
   ],
   "source": [
    "data = data_generator(train_data)\n",
    "all_data = []\n",
    "for data_object in data:\n",
    "    all_data.append(data_object)\n",
    "    \n",
    "# print(all_data[0][0].shape)\n",
    "all_ys = all_data[0][1]\n",
    "all_ys = keras.utils.to_categorical(all_ys, num_classes)\n",
    "# all_ys = to_categorical\n",
    "print(all_ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.4 Design CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "\n",
    "input_im = Input(shape=(input_shape), name='input_im')\n",
    "conv1 = Conv2D(8, kernel_size=(3, 3), strides = (2,2),  activation='relu')(input_im)\n",
    "conv2 = Conv2D(16, (3, 3), strides = (2,2), activation='relu')(conv1)\n",
    "flat = Flatten()(conv2)\n",
    "dense1 = Dense(44, activation='relu')(flat)\n",
    "output_class = Dense(num_classes, activation='softmax')(dense1)\n",
    "\n",
    "model = Model(inputs=input_im, outputs=output_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile model and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'id_model1'\n",
    "\n",
    "if not os.path.exists('./'+model_name):\n",
    "    os.mkdir(model_name)\n",
    "    \n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=adam, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plot_model(model, model_name+'/'+model_name+'.png')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.5 Training model\n",
    "In order to train the model, instead of \"model.fit\" function, we will use \"model.fit_generator\" function for training. For details check out [keras documentation](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRTensorBoard(TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(LRTensorBoard, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs.update({'lr': K.eval(self.model.optimizer.lr)})\n",
    "        super(LRTensorBoard, self).on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = ???\n",
    "    \n",
    "checkpoint = ModelCheckpoint(model_name+'/'+model_name+'-{epoch:02d}-{val_loss:.2f}.h5', \n",
    "                             monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/logs.csv', separator=',', append=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001)\n",
    "tensorboard = LRTensorBoard(log_dir='./'+model_name, histogram_freq=0, write_graph=True, write_grads=1, \n",
    "                            batch_size=batch_size, write_images=True)\n",
    "\n",
    "callbacks = [checkpoint, tensorboard, cvslogger, reducelr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1.5.1 \n",
    "Train model without using any pre-processing scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_generator(x_train, y_train, batch_size, preprocessing = None)\n",
    "val_gen = data_generator(x_val, y_val, batch_size)\n",
    "test_gen = data_generator(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y= val_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = model.fit_generator(train_gen, epochs=epochs, steps_per_epoch=len(y_train)//batch_size, \n",
    "                           validation_data=val_gen, validation_steps=len(y_val)//batch_size, \n",
    "                           callbacks=callbacks, verbose=1)\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 1.5.2 \n",
    "Train model by using data preprocessing i.e normalization or mean shift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "# Add your code here\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2.1 Pooling\n",
    "Now, you need to modify the model by adding pooling layer(s). Pooling could be average pooling or max pooling. You can use the size and stride for pooling of your choice. \n",
    "<br> \n",
    "Modify the network by introducing pooling layer and train the model using __fit_generator__ function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "# Add your code here\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.1 Dropout\n",
    "Modify the network by introducing dropout layer and train the model using __fit_generator__ function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "# Add your code here\n",
    "\n",
    "# save model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4.1 Batch Normalization\n",
    "Modify the network by introducing batch normalization layer and train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "# Add your code to complete this cell\n",
    "\n",
    "model_name = 'id_model41'\n",
    "if not os.path.exists('./'+model_name):\n",
    "    os.mkdir(model_name)\n",
    "    \n",
    "# ====================================================   \n",
    "input_im = Input(shape=(input_shape), name='input_im')\n",
    "\n",
    "# Hidden Layers\n",
    "\n",
    "output_class = Dense(num_classes, activation='softmax')(dense1)\n",
    "model = Model(inputs=input_im, outputs=output_class)\n",
    "# ====================================================\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=adam, \n",
    "              metrics=['accuracy'])\n",
    "plot_model(model, model_name+'/'+model_name+'.png')\n",
    "model.summary()\n",
    "\n",
    "hist_41 = model.fit_generator(train_gen, epochs=epochs, steps_per_epoch=len(y_train)//batch_size, \n",
    "                           validation_data=val_gen, validation_steps=len(y_val)//batch_size, \n",
    "                           callbacks=callbacks, verbose=1)\n",
    "\n",
    "# save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5.1 Comparision of all model\n",
    "\n",
    "In this task you need to plot the loss and accuracy for all models and __discuss__ which model has better performance and why.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Accuracy of all models\n",
    "plt.clf() \n",
    "x_axis = list(range(epochs))\n",
    "plt.plot(x_axis, hist1.history['acc'], label='acc1')\n",
    "plt.scatter(x_axis, hist1.history['acc'])\n",
    "plt.plot(x_axis, hist2.history['acc'], label='acc2')\n",
    "plt.scatter(x_axis, hist2.history['acc'])\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot loss of all models\n",
    "plt.clf() \n",
    "x_axis = list(range(epochs))\n",
    "plt.plot(x_axis, hist1.history['loss'], label='loss1')\n",
    "plt.scatter(x_axis, hist1.history['loss'])\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tensorboard \n",
    "\n",
    "You can run TensorBoard using the following command\n",
    "```tensorboard --logdir=path/to/log-directory\n",
    "```\n",
    "Now for logs of all above trained models, take snapshot of the _loss_ and _accuracy_ plots and save in the directory where this notebook is. To show that saved plot here in notebook use following command in _markdown_ cell. \n",
    "<br> __![](path_to_image)__\n",
    "\n",
    "- Tensorboard plot of accuracies:\n",
    "!['loss'](loss.png)\n",
    "\n",
    "- Tensorboard plot of accuracies:\n",
    "!['Accuracy](acc.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADD Your Comments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5.2 Visualize Activations\n",
    "In this task, you are required to visualize the activations (outputs) of both the convolution layers of a model. For help, please refer to __Tutorials__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6.1  Effect of learning rate\n",
    "\n",
    "Take the best selected model in __Task 5.1__ and change its learning rate to: \n",
    "- 6.1.1 any value between 5 and 1.\n",
    "- 6.1.2 learning rate = any value between 0.6 and  0.1 \n",
    "- 6.1.3 learning rate = 0.00001\n",
    "\n",
    "and train these three models to compare the effect learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Task 6.2 Plot loss and accuracy\n",
    "\n",
    "Plot the loss and accracy for best model selected in task 5.1, and model trained in 6.1.1, 6.1.2 and 6.1.3 task. Give the detailed analysis of the effect of learning rate in your words and select the best learning rate for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
